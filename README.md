# VoiceAI-takeHome - Document Conversation Agent

## Overview

VoiceAI is an advanced web application that enables users to have voice conversations with AI about uploaded documents. This project leverages LiveKit's real-time communication technology combined with various AI services to create an intuitive voice assistant that can understand, analyze, and discuss document contents with users.

## Features

- üìÑ **Document Upload & Analysis**: Upload PDF documents for AI processing
- üó£Ô∏è **Voice Conversations**: Natural voice interaction with the AI about document contents
- üéß **Real-time Audio Processing**: Krisp noise filtering for clear communication
- üß† **Intelligent Context Awareness**: AI retains context of the uploaded document throughout the conversation
- üíª **Modern UI**: Beautiful and responsive interface built with Next.js and Tailwind CSS

## Tech Stack

### Frontend

- [Next.js](https://nextjs.org/) (v15) - React framework for server-side rendering and static site generation
- [React](https://reactjs.org/) (v19) - JavaScript library for building user interfaces
- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [Framer Motion](https://www.framer.com/motion/) - Animation library for React
- [LiveKit Components](https://github.com/livekit/components-js) - React components for real-time communication

### Backend

- [Python](https://www.python.org/) - For the AI agent implementation
- [LiveKit Agents](https://github.com/livekit/agents) - SDK for building LiveKit agents
- [Groq](https://groq.com/) - AI services for STT (Speech-to-Text), LLM (Language Model), and TTS (Text-to-Speech)
- [Silero VAD](https://github.com/snakers4/silero-vad) - Voice Activity Detection

### File Processing

- [PDF2JSON](https://www.npmjs.com/package/pdf2json) - For extracting text from PDF documents

## Prerequisites

- [Node.js](https://nodejs.org/) v18 or higher
- [Python](https://www.python.org/) v3.9 or higher
- [LiveKit Account](https://livekit.io/) for API key and secret
- [Groq API Key](https://console.groq.com/) for AI services

## Installation

### 1. Clone the repository

```bash
git clone [repository-url]
cd voiceai-takehome
```

### 2. Install frontend dependencies

```bash
npm install
```

### 3. Set up Python environment for the agent

```bash
# Navigate to agent directory
cd agent

# Create a Python virtual environment (if it doesn't exist)
python -m venv venv

# Activate the virtual environment
.\venv\Scripts\Activate.ps1

# Install Python dependencies from requirements.txt
pip install -r requirements.txt

# Download required model files
python agent.py download-files

# Start the agent in development mode
python agent.py dev
```

The `requirements.txt` file includes all necessary Python dependencies for the voice agent:

- LiveKit agent packages with support for Groq AI services
- LiveKit noise cancellation plugin
- Additional utilities like dotenv for environment variable management

### 4. Configure environment variables

Create a `.env.local` file in the root directory with the following variables:

```
# LiveKit settings
LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret
LIVEKIT_URL=your_livekit_url


# Groq API key
GROQ_API_KEY=your_groq_api_key

# Next.js specific
NEXT_PUBLIC_CONN_DETAILS_ENDPOINT=/api/connection-details
```

## Running the Application

### Development Mode

1. Start the Next.js frontend:

```bash
npm run dev
```

2. In a separate terminal, start the agent:

```bash
cd agent
.\venv\Scripts\Activate.ps1
python agent.py dev
```

### Production Mode

1. Build the Next.js application:

```bash
npm run build
```

2. Start the production server:

```bash
npm run start
```

3. Start the agent in production mode:

```bash
cd agent
.\venv\Scripts\Activate.ps1
python agent.py start
```

## Usage

1. Open the application in your browser (default is `http://localhost:3000`)
2. Upload a PDF document using the file upload interface
3. Once the document is processed, click "Connect" to start the voice assistant
4. Speak naturally to ask questions about the document content
5. The AI will respond with information based on the document

## System Requirements

- **Browser:** Latest version of Chrome, Firefox, or Edge with WebRTC support
- **Microphone:** Required for voice interaction with the AI
- **Internet Connection:** Good connection required for real-time voice communication

## Troubleshooting

- If you encounter microphone permission issues, ensure your browser has permission to access your microphone
- If the agent isn't responding, check the terminal running the Python agent for any error messages
- For connection issues, verify your LiveKit credentials and internet connectivity

## Project Structure

```
‚îú‚îÄ‚îÄ agent/               # Python agent code
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt # Python dependencies
‚îú‚îÄ‚îÄ public/              # Static assets
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/             # Next.js app directory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/         # API routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/  # App-specific components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/       # Custom React hooks
‚îÇ   ‚îú‚îÄ‚îÄ components/      # Shared React components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/          # UI component library
‚îÇ   ‚îú‚îÄ‚îÄ lib/             # Utility functions
‚îú‚îÄ‚îÄ .env.local           # Environment variables (not in repository)
‚îî‚îÄ‚îÄ package.json         # Project dependencies
```

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements

- [LiveKit](https://livekit.io/) for real-time communication infrastructure
- [Groq](https://groq.com/) for AI services
- [Silero Team](https://github.com/snakers4/silero-vad) for Voice Activity Detection
